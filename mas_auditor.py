# -*- coding: utf-8 -*-
"""MAS_AUDITOR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmeF-83oOSeELXwfAmJ5bDwYj7tLjSMR

**The code(Google colab version) is a RAG-based MultiAgent System for Auditing Smart Contracts**
"""

#Installing required libraries

!pip install python-dotenv
!pip install --upgrade llama-index
!pip install openai
!pip install --upgrade anthropic
!pip install llama-index requests transformers

from google.colab import files
import zipfile
import os

# Upload the ZIP file
uploaded = files.upload()

# Extract the ZIP file
zip_filename = list(uploaded.keys())[0]
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall('./')  # Extract to the current directory

# Confirm extraction
print("Extracted files:", os.listdir('./'))

# Load the .env file
from dotenv import load_dotenv # Import load_dotenv from the dotenv package
import os # Import os module for environment variable management
load_dotenv('/content/api_k.env')

# Get API keys from environment variables using os.getenv
API_KEY_1 = os.getenv('API_KEY_1') # Assign the value from environment variable to API_KEY_1
API_KEY_2 = os.getenv('API_KEY_2') # Assign the value from environment variable to API_KEY_2

import openai
import os
import hashlib  # Needed for creating unique contract identifiers.
from anthropic import Anthropic
import matplotlib.pyplot as plt
from google.colab import files
from dotenv import load_dotenv
from fpdf import FPDF
import re
import requests

from llama_index.core import (
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
    Document,
    SimpleDirectoryReader
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

# ---------------------------
# Load Environment Variables and API Keys
# ---------------------------
load_dotenv('/content/API_AI_Keys.env')
openai.api_key = os.getenv("API_KEY_1")
anthropic_api_key = os.getenv("API_KEY_2")
anthropic_client = Anthropic(api_key=anthropic_api_key)

# ---------------------------
# Step 1: Load Documents from Local Folders and GitHub
# ---------------------------
AUDIT_FOLDER = "/content/Smart_contracts_findings/findings"      # Folder with audit findings
CONTRACT_FOLDER = "/content/Smart_contracts_findings/contracts"    # Folder with smart contracts

def load_documents_from_folder(folder_path):
    documents = {}
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, 'r') as file:
            documents[filename] = file.read()
    return documents

# Load local documents
audit_docs = load_documents_from_folder(AUDIT_FOLDER)
contract_docs = load_documents_from_folder(CONTRACT_FOLDER)

# Build separate GitHub documents dictionary
GITHUB_LINKS = {
    "link1": "https://github.com/sirhashalot/SCV-List",
    "link2": "https://hacken.io/discover/smart-contract-vulnerabilities/",
    "link3": "https://github.com/example/bug1"
}

def load_documents_from_github(links):
    documents = {}
    for idx, link in enumerate(links):
        try:
            response = requests.get(link)
            if response.status_code == 200:
                documents[f"github_doc_{idx+1}"] = response.text
            else:
                documents[f"github_doc_{idx+1}"] = ""
        except Exception as e:
            documents[f"github_doc_{idx+1}"] = ""
    return documents

github_docs = load_documents_from_github(GITHUB_LINKS.values())

# Combine only audit and contract documents for the main index
all_docs = {**audit_docs, **contract_docs}
print(f"Loaded {len(all_docs)} documents for main index.")
print(f"Loaded {len(github_docs)} GitHub documents separately.")

# ---------------------------
# Step 2: Create Separate Indices (Main and GitHub)
# ---------------------------
# Convert all_docs into a list of Document objects
documents_list = []
for filename, content in all_docs.items():
    if content.strip():
        documents_list.append(Document(text=content, metadata={"source": filename}))

INDEX_PATH = "/content/index"
GITHUB_INDEX_PATH = "/content/github_index"

# Configure LLM and embedding model
llm = OpenAI(temperature=0, model_name="gpt-4o-2024-08-06")
embed_model = OpenAIEmbedding(model="text-embedding-ada-002")

# Create or load the main index (from local audits & contracts)
if os.path.exists(os.path.join(INDEX_PATH, "docstore.json")):
    print(f"Loading existing main index from {INDEX_PATH}...")
    storage_context = StorageContext.from_defaults(persist_dir=INDEX_PATH)
    index = load_index_from_storage(storage_context, llm=llm, embed_model=embed_model)
else:
    print(f"Creating a new main index at {INDEX_PATH}...")
    os.makedirs(INDEX_PATH, exist_ok=True)
    index = VectorStoreIndex.from_documents(documents_list, llm=llm, embed_model=embed_model)
    index.storage_context.persist(persist_dir=INDEX_PATH)
    print("Main index created and stored.")

# Create or load the GitHub index separately
github_documents_list = []
for filename, content in github_docs.items():
    if content.strip():
        github_documents_list.append(Document(text=content, metadata={"source": filename}))

if os.path.exists(os.path.join(GITHUB_INDEX_PATH, "docstore.json")):
    print(f"Loading existing GitHub index from {GITHUB_INDEX_PATH}...")
    storage_context = StorageContext.from_defaults(persist_dir=GITHUB_INDEX_PATH)
    github_index = load_index_from_storage(storage_context, llm=llm, embed_model=embed_model)
else:
    print(f"Creating a new GitHub index at {GITHUB_INDEX_PATH}...")
    os.makedirs(GITHUB_INDEX_PATH, exist_ok=True)
    github_index = VectorStoreIndex.from_documents(github_documents_list, llm=llm, embed_model=embed_model)
    github_index.storage_context.persist(persist_dir=GITHUB_INDEX_PATH)
    print("GitHub index created and stored.")

# ---------------------------
# Step 3: Define RAG-based Audit Functions with Chunking
# ---------------------------
def summarize_audit_context(audit_context):
    prompt = f"Please summarize the following audit information, focusing on key findings and recommendations:\n\n{audit_context}"
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[
                {"role": "system", "content": "You are an expert in smart contract security."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000
        )
        if response.choices and len(response.choices) > 0:
            return response.choices[0].message.content
        else:
            return "No summary generated. Please try again."
    except Exception as e:
        return f"Summarization error: {str(e)}"

def retrieve_relevant_audits(index, smart_contract_code, top_k=1):
    # Chunk the smart contract code if it's too long
    chunk_size = 4000  # Adjust this value as needed
    chunks = [smart_contract_code[i:i + chunk_size] for i in range(0, len(smart_contract_code), chunk_size)]
    retrieved_audits = []
    for chunk in chunks:
        query = f"Find the most relevant audit information for the following smart contract code:\n{chunk}"
        query_engine = index.as_query_engine(similarity_top_k=top_k)
        response = query_engine.query(query)
        retrieved_audits.extend(response.source_nodes)
    return retrieved_audits

report_cache = {}  # Initialize report cache

def actor_generate_report(smart_contract_code, retrieved_audits):
    contract_hash = hashlib.sha256(smart_contract_code.encode()).hexdigest()
    if contract_hash in report_cache:
        return report_cache[contract_hash]

    # Extract context text from retrieved source nodes
    audit_context = "\n\n".join([doc.node.text for doc in retrieved_audits if hasattr(doc, "node") and hasattr(doc.node, "text")])
    # Summarize the audit context to reduce token count
    summarized_audit_context = summarize_audit_context(audit_context)

    prompt = f"""Analyze the following smart contract code using the benchmark audit context below and generate
    a detailed report in JSON format following this structure.

**Benchmark Audits:**
{summarized_audit_context}

**Smart Contract Code:**
{smart_contract_code}

```json
{{
    "findings": [
        {{
            "Issue": "Short description of the issue",
            "Severity": "High/Medium/Low/Info/Best Practices",
            "Contracts": ["ContractName.sol"],
            "Description": "Detailed description of the issue. Example:\\n```solidity\\nfunction vulnerable() {{\\n // show exact vulnerable code here\\n}}\\n```\\nExplain why this is vulnerable...",
            "Recommendation": ""
        }}
    ]
}}

```
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[
                {"role": "system", "content": "You are an expert in smart contract security."},
                {"role": "user", "content": prompt}
            ],

        )
        if response.choices and len(response.choices) > 0:
            report = response.choices[0].message.content
            report_cache[contract_hash] = report
            return report
        else:
            return "No response generated by the model. Please try again."
    except Exception as e:
        return f"An error occurred: {str(e)}"

def critic_evaluate_report(report, smart_contract_code):
    prompt = f"""Evaluate the following vulnerability report for the provided smart contract code and provide actionable feedback:

Report:
{report}

Code:
{smart_contract_code}

Provide detailed feedback including:
1. Overall score (0-10)
2. Accuracy score (0-10)
3. Clarity score (0-10)
4. Specific vulnerabilities missed with explanations
5. Incorrectly identified vulnerabilities with explanations
6. Suggestions for improving clarity and organization
7. Concrete code changes for mitigation
8. Specific, actionable recommendations for improvement.

Ensure your feedback is detailed and professional.
"""
    try:
        response = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            system="You are a helpful assistant.",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
        )
        if response.content:
            return response.content[0].text if response.content else "No response generated by the model. Please try again."
        else:
            return "No response generated by the model. Please try again."
    except Exception as e:
        return f"An error occurred: {str(e)}"

def parse_feedback(critic_feedback):
    try:
        lines = critic_feedback.split("\n")
        score_line = next(line for line in lines if "Score:" in line)
        score = int(score_line.split(":")[-1].strip().split("/")[0])
        feedback_start = lines.index(score_line) + 1
        detailed_feedback = "\n".join(lines[feedback_start:])
        return score, detailed_feedback
    except Exception as e:
        print(f"Error parsing feedback: {str(e)}")
        return 0, critic_feedback

def simple_rl_feedback(actor_report, critic_feedback):
    score, feedback = parse_feedback(critic_feedback)
    revised_prompt = f"""Revise your vulnerability report based on the following feedback:

Feedback:
{feedback}

Original Report:
{actor_report}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[
                {"role": "system", "content": "You are an expert in revising smart contract reports based on feedback."},
                {"role": "user", "content": revised_prompt}
            ],

        )
        if response.choices and len(response.choices) > 0:
            revised_report = response.choices[0].message.content
            return revised_report, score
        else:
            return actor_report, score
    except Exception as e:
        return f"An error occurred: {str(e)}", 0

    revised_report, score = simple_rl_feedback(actor_report, critic_feedback)

       # Try to parse as JSON; if it fails, reformat
    try:
           json_report = json.loads(revised_report)  # Try parsing directly
           return json.dumps(json_report, indent=4), score  # Reformat for consistent indentation
    except json.JSONDecodeError:
           # If not valid JSON, attempt to extract and reformat
           report_match = re.search(r'\{(.*?)\}', revised_report, re.DOTALL)
           if report_match:
               try:
                   json_data = json.loads("{" + report_match.group(1) + "}")
                   return json.dumps(json_data, indent=4), score
               except json.JSONDecodeError:
                   print("Warning: Could not reformat report into valid JSON.")
                   return revised_report, score

def smart_contract_audit():
    # Choose input method: upload file or copy-paste code
    input_choice = input("Choose input method:\n1. Upload file\n2. Copy-paste code\n")
    if input_choice == "1":
        uploaded = files.upload()
        file_name = list(uploaded.keys())[0]
        with open(file_name, 'r') as file:
            smart_contract_code = file.read()
    elif input_choice == "2":
        smart_contract_code = input("Please paste your smart contract code here:\n")
    else:
        print("Invalid choice. Exiting.")
        return

    # Retrieve relevant audits using chunking from main index
    retrieved_audits = retrieve_relevant_audits(index, smart_contract_code, top_k=2)

    # Generate the audit report using the actor function
    actor_report = actor_generate_report(smart_contract_code, retrieved_audits)
    critic_feedback = critic_evaluate_report(actor_report, smart_contract_code)
    final_report, score = simple_rl_feedback(actor_report, critic_feedback)

    print("\n--- Final Audit Report ---")
    print(final_report)
    print(f"Score: {score}")

    # Save final report as a PDF for download
    class PDF(FPDF):
        def header(self):
            self.set_font('Arial', 'B', 16)
            self.cell(0, 10, 'Smart Contract Audit Report', 0, 1, 'C')
            self.ln(10)
        def footer(self):
            self.set_y(-15)
            self.set_font('Arial', 'I', 8)
            self.cell(0, 10, 'Page ' + str(self.page_no()), 0, 0, 'C')

    pdf = PDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.multi_cell(0, 10, final_report)
    pdf_file = "final_audit_report.pdf"
    pdf.output(pdf_file)
    print(f"Final audit report saved as {pdf_file}")
    files.download(pdf_file)

if __name__ == "__main__":
    smart_contract_audit()